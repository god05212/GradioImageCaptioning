import gradio as gr
from transformers import pipeline
from PIL import Image

# Image-to-Text íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (BLIP ëª¨ë¸ ì‚¬ìš©)
# ë” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜ device_map="auto"ë¥¼ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ ì œì•½ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    image_to_text = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base", device_map="auto")
except Exception as e:
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("ë” ì‘ì€ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤: nlpconnect/vit-gpt2-image-captioning")
    image_to_text = pipeline("image-to-text", model="nlpconnect/vit-gpt2-image-captioning", device_map="auto")


def analyze_image(image):
    if image is None:
        return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    try:
        # PIL Image ê°ì²´ë¥¼ ëª¨ë¸ì— ì „ë‹¬
        text_description = image_to_text(image)[0]['generated_text']
        return f"ì´ë¯¸ì§€ ì„¤ëª…: {text_description}"
    except Exception as e:
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •
iface = gr.Interface(
    fn=analyze_image,
    inputs=gr.Image(type="pil", label="ì´ë¯¸ì§€ ì—…ë¡œë“œ"), # PIL Image ê°ì²´ë¡œ ë°›ë„ë¡ ì„¤ì •
    outputs="text",
    title="ğŸ“¸ ì´ë¯¸ì§€ ì„¤ëª… AI ì±—ë´‡",
    description="ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì‹œë©´ AIê°€ ì´ë¯¸ì§€ ë‚´ìš©ì„ ì„¤ëª…í•´ ë“œë¦½ë‹ˆë‹¤."
)

# Gradio ì•± ì‹¤í–‰
iface.launch(share=True)
